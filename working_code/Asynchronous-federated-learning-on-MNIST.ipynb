{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Asynchronous federated learning on MNIST\n",
    "\n",
    "This notebook will go through the steps to run a federated learning via websocket workers in an asynchronous way using [TrainConfig](https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/advanced/Federated%20Learning%20with%20TrainConfig/Introduction%20to%20TrainConfig.ipynb). We will use federated averaging to join the remotely trained models.\n",
    "\n",
    "Authors:\n",
    "- Silvia - GitHub [@midokura-silvia](https://github.com/midokura-silvia)\n",
    "- Marianne Monteiro - Twitter [@hereismari](https://twitter.com/hereismari) - Github [@mari-linhares\n",
    "](https://github.com/mari-linhares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning setup\n",
    "\n",
    "For a Federated Learning setup with TrainConfig we need different participants:\n",
    "\n",
    "* _Workers_ that own datasets.\n",
    "\n",
    "* An entity that knows the workers and the dataset name that lives in each worker. We'll call this a _scheduler_.\n",
    "\n",
    "Each worker is represented by two parts, a proxy local to the scheduler (websocket client worker) and the remote instance that holds the data and performs the computations. The remote part is called a websocket server worker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Start the websocket workers\n",
    "So first, we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook):\n",
    "\n",
    "```bash\n",
    "python start_websocket_servers.py\n",
    "```\n",
    "\n",
    "#### What's going on?\n",
    "\n",
    "The script will instantiate three workers, Alice, Bob and Charlie and prepare their local data. \n",
    "Each worker is set up to have a subset of the MNIST training dataset. \n",
    "Alice holds all images corresponding to the digits 0-3, \n",
    "Bob holds all images corresponding to the digits 4-6 and \n",
    "Charlie holds all images corresponding to the digits 7-9.\n",
    "\n",
    "| Worker      | Digits in local dataset | Number of samples |\n",
    "| ----------- | ----------------------- | ----------------- |\n",
    "| Alice       | 0-3                     | 24754             |\n",
    "| Bob         | 4-6                     | 17181             |\n",
    "| Charlie     | 7-9                     | 18065             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following to see the code of the function that starts a worker\n",
    "# import run_websocket_server\n",
    "\n",
    "# print(inspect.getsource(run_websocket_server.start_websocket_server_worker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing let's first need to import dependencies, setup needed arguments and configure logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0817 12:55:04.001699 140693455689472 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/deeplearning/thirdparty_sw/miniconda3/lib/python3.7/site-packages/tf_encrypted-0.5.7rc1-py3.7-linux-x86_64.egg/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
      "W0817 12:55:04.085219 140693455689472 deprecation_wrapper.py:119] From /home/deeplearning/thirdparty_sw/miniconda3/lib/python3.7/site-packages/tf_encrypted-0.5.7rc1-py3.7-linux-x86_64.egg/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "import syft as sy\n",
    "from syft.workers import WebsocketClientWorker\n",
    "from syft.frameworks.torch.federated import utils\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import run_websocket_client as rwc\n",
    "if torch.__version__>= \"1.0.2\":\n",
    "    raise ValueError(f\"This tutorial currently does not support torch versions >= 1.0.2, you have version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook torch\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, cuda=False, federate_after_n_batches=10, lr=0.1, save_model=True, seed=1, test_batch_size=128, training_rounds=40, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "args = rwc.define_and_get_arguments(args=[])\n",
    "use_cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "args.save_model = True\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"run_websocket_client\")\n",
    "\n",
    "if not len(logger.handlers):\n",
    "    FORMAT = \"%(asctime)s - %(message)s\"\n",
    "    DATE_FMT = \"%H:%M:%S\"\n",
    "    formatter = logging.Formatter(FORMAT, DATE_FMT)\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.propagate = False\n",
    "LOG_LEVEL = logging.DEBUG\n",
    "logger.setLevel(LOG_LEVEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client workers, our local proxies to the remote workers.\n",
    "Note that **this step will fail, if the websocket server workers are not running**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<WebsocketClientWorker id:alice #objects local:0 #objects remote: 0>, <WebsocketClientWorker id:bob #objects local:0 #objects remote: 0>, <WebsocketClientWorker id:charlie #objects local:0 #objects remote: 0>]\n"
     ]
    }
   ],
   "source": [
    "kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket)\n",
    "bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket)\n",
    "charlie = WebsocketClientWorker(id=\"charlie\", port=8779, **kwargs_websocket)\n",
    "testing = WebsocketClientWorker(id=\"testing\", port=8780,  **kwargs_websocket)\n",
    "\n",
    "worker_instances = [alice, bob, charlie]\n",
    "print(worker_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Let's instantiate the machine learning model. It is a small neural network with 2 convolutional and two fully connected layers. \n",
    "It uses ReLU activations and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
      "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
      "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
      "        self.fc2 = nn.Linear(500, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = F.relu(self.conv1(x))\n",
      "        x = F.max_pool2d(x, 2, 2)\n",
      "        x = F.relu(self.conv2(x))\n",
      "        x = F.max_pool2d(x, 2, 2)\n",
      "        x = x.view(-1, 4 * 4 * 50)\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = self.fc2(x)\n",
      "        return F.log_softmax(x, dim=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(rwc.Net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = rwc.Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "\n",
    "The training data lives in each of the devices, but fefore starting the training, let's load the MNIST test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\n",
    "            \"./data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "(data, target) = test_loader.__iter__().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the model serializable\n",
    "\n",
    "In order to send the model to the workers we need the model to be serializable, for this we use [`jit`](https://pytorch.org/docs/stable/jit.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start the training\n",
    "\n",
    "Now we are ready to start the federated training. We will perform training over a given number of batches separately on each worker and then calculate the federated average of the resulting model.\n",
    "\n",
    "Every 10th training round we will evaluate the performance of the models returned by the workers and of the model obtained by federated averaging. \n",
    "\n",
    "The performance will be given both as the accuracy (ratio of correct predictions) and as the histograms of predicted digits. This is of interest, as each worker only owns a subset of the digits. Therefore, in the beginning each worker will only predict their numbers and only know about the other numbers via the federated averaging process.\n",
    "\n",
    "The training is done in an asynchronous manner. This means that the scheduler just tell the workers to train and does not block to wait for the result of the training before talking to the next worker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the training are given in the arguments. \n",
    "Each worker will train on a given number of batches, given by the value of federate_after_n_batches.\n",
    "The training batch size and learning rate are also configured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federate_after_n_batches: 10\n",
      "Batch size: 32\n",
      "Initial learning rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Federate_after_n_batches: \" + str(args.federate_after_n_batches))\n",
    "print(\"Batch size: \" + str(args.batch_size))\n",
    "print(\"Initial learning rate: \" + str(args.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:39 - Starting training round 1/40\n",
      "12:55:39 - Training round 1, calling fit on worker: alice\n",
      "12:55:40 - Training round 1, calling fit on worker: bob\n",
      "12:55:40 - Training round 1, calling fit on worker: charlie\n",
      "12:55:42 - Training round: 1, worker: bob, avg_loss: tensor(1.1538, grad_fn=<MeanBackward1>)\n",
      "12:55:44 - Training round: 1, worker: alice, avg_loss: tensor(0.5856, grad_fn=<MeanBackward1>)\n",
      "12:55:45 - Training round: 1, worker: charlie, avg_loss: tensor(1.3963, grad_fn=<MeanBackward1>)\n",
      "12:55:50 - alice: Prediction hist.: [ 7862  991  1147  0  0  0  0  0  0  0]\n",
      "12:55:50 - alice: Percentage numbers 0-3: 1.0\n",
      "12:55:50 - alice: Percentage numbers 4-6: 0.0\n",
      "12:55:50 - alice: Percentage numbers 7-9: 0.0\n",
      "12:55:50 - alice: Test set: Average loss: 0.0446, Accuracy: 2273/10000 (22.73)\n",
      "12:55:56 - bob: Prediction hist.: [ 0  0  0  0  10000  0  0  0  0  0]\n",
      "12:55:56 - bob: Percentage numbers 0-3: 0.0\n",
      "12:55:56 - bob: Percentage numbers 4-6: 1.0\n",
      "12:55:56 - bob: Percentage numbers 7-9: 0.0\n",
      "12:55:56 - bob: Test set: Average loss: 0.0345, Accuracy: 982/10000 (9.82)\n",
      "12:55:59 - charlie: Prediction hist.: [ 0  0  0  0  0  0  0  5599  0  4401]\n",
      "12:55:59 - charlie: Percentage numbers 0-3: 0.0\n",
      "12:55:59 - charlie: Percentage numbers 4-6: 0.0\n",
      "12:55:59 - charlie: Percentage numbers 7-9: 1.0\n",
      "12:55:59 - charlie: Test set: Average loss: 0.0304, Accuracy: 1229/10000 (12.29)\n",
      "12:56:03 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "12:56:03 - Federated model: Prediction hist.: [ 85  38  0  0  114  8  0  9749  0  6]\n",
      "12:56:03 - Federated model: Percentage numbers 0-3: 0.0123\n",
      "12:56:03 - Federated model: Percentage numbers 4-6: 0.0122\n",
      "12:56:03 - Federated model: Percentage numbers 7-9: 0.9755\n",
      "12:56:03 - Federated model: Test set: Average loss: 0.0177, Accuracy: 1158/10000 (11.58)\n",
      "12:56:03 - Starting training round 2/40\n",
      "12:56:03 - Training round 2, calling fit on worker: alice\n",
      "12:56:03 - Training round 2, calling fit on worker: bob\n",
      "12:56:03 - Training round 2, calling fit on worker: charlie\n",
      "12:56:04 - Training round: 2, worker: alice, avg_loss: tensor(1.2036, grad_fn=<MeanBackward1>)\n",
      "12:56:06 - Training round: 2, worker: charlie, avg_loss: tensor(1.5045, grad_fn=<MeanBackward1>)\n",
      "12:56:07 - Training round: 2, worker: bob, avg_loss: tensor(1.6185, grad_fn=<MeanBackward1>)\n",
      "12:56:08 - Starting training round 3/40\n",
      "12:56:09 - Training round 3, calling fit on worker: alice\n",
      "12:56:09 - Training round 3, calling fit on worker: bob\n",
      "12:56:09 - Training round 3, calling fit on worker: charlie\n",
      "12:56:10 - Training round: 3, worker: charlie, avg_loss: tensor(1.8525, grad_fn=<MeanBackward1>)\n",
      "12:56:11 - Training round: 3, worker: alice, avg_loss: tensor(1.2724, grad_fn=<MeanBackward1>)\n",
      "12:56:12 - Training round: 3, worker: bob, avg_loss: tensor(0.6778, grad_fn=<MeanBackward1>)\n",
      "12:56:13 - Starting training round 4/40\n",
      "12:56:14 - Training round 4, calling fit on worker: alice\n",
      "12:56:14 - Training round 4, calling fit on worker: bob\n",
      "12:56:14 - Training round 4, calling fit on worker: charlie\n",
      "12:56:15 - Training round: 4, worker: bob, avg_loss: tensor(1.6517, grad_fn=<MeanBackward1>)\n",
      "12:56:16 - Training round: 4, worker: charlie, avg_loss: tensor(0.7665, grad_fn=<MeanBackward1>)\n",
      "12:56:17 - Training round: 4, worker: alice, avg_loss: tensor(0.3556, grad_fn=<MeanBackward1>)\n",
      "12:56:22 - alice: Prediction hist.: [ 3302  2415  1759  2524  0  0  0  0  0  0]\n",
      "12:56:22 - alice: Percentage numbers 0-3: 1.0\n",
      "12:56:22 - alice: Percentage numbers 4-6: 0.0\n",
      "12:56:22 - alice: Percentage numbers 7-9: 0.0\n",
      "12:56:22 - alice: Test set: Average loss: 0.0211, Accuracy: 3843/10000 (38.43)\n",
      "12:56:25 - bob: Prediction hist.: [ 0  290  2  0  4096  4078  1534  0  0  0]\n",
      "12:56:25 - bob: Percentage numbers 0-3: 0.0292\n",
      "12:56:25 - bob: Percentage numbers 4-6: 0.9708\n",
      "12:56:25 - bob: Percentage numbers 7-9: 0.0\n",
      "12:56:25 - bob: Test set: Average loss: 0.0159, Accuracy: 2912/10000 (29.12)\n",
      "12:56:28 - charlie: Prediction hist.: [ 0  0  0  0  0  0  0  1403  6193  2404]\n",
      "12:56:28 - charlie: Percentage numbers 0-3: 0.0\n",
      "12:56:28 - charlie: Percentage numbers 4-6: 0.0\n",
      "12:56:28 - charlie: Percentage numbers 7-9: 1.0\n",
      "12:56:28 - charlie: Test set: Average loss: 0.0292, Accuracy: 2597/10000 (25.97)\n",
      "12:56:31 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "12:56:31 - Federated model: Prediction hist.: [ 1952  1418  1271  304  19  0  476  679  984  2897]\n",
      "12:56:31 - Federated model: Percentage numbers 0-3: 0.4945\n",
      "12:56:31 - Federated model: Percentage numbers 4-6: 0.0495\n",
      "12:56:31 - Federated model: Percentage numbers 7-9: 0.456\n",
      "12:56:31 - Federated model: Test set: Average loss: 0.0135, Accuracy: 5676/10000 (56.76)\n",
      "12:56:31 - Starting training round 5/40\n",
      "12:56:32 - Training round 5, calling fit on worker: alice\n",
      "12:56:32 - Training round 5, calling fit on worker: bob\n",
      "12:56:32 - Training round 5, calling fit on worker: charlie\n",
      "12:56:33 - Training round: 5, worker: bob, avg_loss: tensor(0.2343, grad_fn=<MeanBackward1>)\n",
      "12:56:34 - Training round: 5, worker: charlie, avg_loss: tensor(0.5752, grad_fn=<MeanBackward1>)\n",
      "12:56:36 - Training round: 5, worker: alice, avg_loss: tensor(0.0663, grad_fn=<MeanBackward1>)\n",
      "12:56:38 - Starting training round 6/40\n",
      "12:56:38 - Training round 6, calling fit on worker: alice\n",
      "12:56:39 - Training round 6, calling fit on worker: bob\n",
      "12:56:39 - Training round 6, calling fit on worker: charlie\n",
      "12:56:40 - Training round: 6, worker: bob, avg_loss: tensor(0.0764, grad_fn=<MeanBackward1>)\n",
      "12:56:41 - Training round: 6, worker: charlie, avg_loss: tensor(0.4452, grad_fn=<MeanBackward1>)\n",
      "12:56:43 - Training round: 6, worker: alice, avg_loss: tensor(0.0784, grad_fn=<MeanBackward1>)\n",
      "12:56:44 - Starting training round 7/40\n",
      "12:56:45 - Training round 7, calling fit on worker: alice\n",
      "12:56:45 - Training round 7, calling fit on worker: bob\n",
      "12:56:45 - Training round 7, calling fit on worker: charlie\n",
      "12:56:46 - Training round: 7, worker: bob, avg_loss: tensor(0.1194, grad_fn=<MeanBackward1>)\n",
      "12:56:47 - Training round: 7, worker: charlie, avg_loss: tensor(1.1165, grad_fn=<MeanBackward1>)\n",
      "12:56:51 - Training round: 7, worker: alice, avg_loss: tensor(0.2400, grad_fn=<MeanBackward1>)\n",
      "12:56:56 - alice: Prediction hist.: [ 1649  1124  2585  4642  0  0  0  0  0  0]\n",
      "12:56:56 - alice: Percentage numbers 0-3: 1.0\n",
      "12:56:56 - alice: Percentage numbers 4-6: 0.0\n",
      "12:56:56 - alice: Percentage numbers 7-9: 0.0\n",
      "12:56:56 - alice: Test set: Average loss: 0.0204, Accuracy: 3983/10000 (39.83)\n",
      "12:57:01 - bob: Prediction hist.: [ 0  228  23  0  5484  2444  1818  3  0  0]\n",
      "12:57:01 - bob: Percentage numbers 0-3: 0.0251\n",
      "12:57:01 - bob: Percentage numbers 4-6: 0.9746\n",
      "12:57:01 - bob: Percentage numbers 7-9: 0.0003\n",
      "12:57:01 - bob: Test set: Average loss: 0.0217, Accuracy: 2995/10000 (29.95)\n",
      "12:57:05 - charlie: Prediction hist.: [ 347  132  24  0  0  0  36  4916  45  4500]\n",
      "12:57:05 - charlie: Percentage numbers 0-3: 0.0503\n",
      "12:57:05 - charlie: Percentage numbers 4-6: 0.0036\n",
      "12:57:05 - charlie: Percentage numbers 7-9: 0.9461\n",
      "12:57:05 - charlie: Test set: Average loss: 0.0195, Accuracy: 2421/10000 (24.21)\n",
      "12:57:09 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "12:57:09 - Federated model: Prediction hist.: [ 1049  1250  1047  962  1025  917  1052  1500  123  1075]\n",
      "12:57:09 - Federated model: Percentage numbers 0-3: 0.4308\n",
      "12:57:09 - Federated model: Percentage numbers 4-6: 0.2994\n",
      "12:57:09 - Federated model: Percentage numbers 7-9: 0.2698\n",
      "12:57:09 - Federated model: Test set: Average loss: 0.0061, Accuracy: 8012/10000 (80.12)\n",
      "12:57:09 - Starting training round 8/40\n",
      "12:57:09 - Training round 8, calling fit on worker: alice\n",
      "12:57:09 - Training round 8, calling fit on worker: bob\n",
      "12:57:09 - Training round 8, calling fit on worker: charlie\n",
      "12:57:10 - Training round: 8, worker: charlie, avg_loss: tensor(0.2839, grad_fn=<MeanBackward1>)\n",
      "12:57:11 - Training round: 8, worker: bob, avg_loss: tensor(0.1473, grad_fn=<MeanBackward1>)\n",
      "12:57:13 - Training round: 8, worker: alice, avg_loss: tensor(0.1223, grad_fn=<MeanBackward1>)\n",
      "12:57:14 - Starting training round 9/40\n",
      "12:57:14 - Training round 9, calling fit on worker: alice\n",
      "12:57:14 - Training round 9, calling fit on worker: bob\n",
      "12:57:14 - Training round 9, calling fit on worker: charlie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:15 - Training round: 9, worker: bob, avg_loss: tensor(0.0543, grad_fn=<MeanBackward1>)\n",
      "12:57:17 - Training round: 9, worker: alice, avg_loss: tensor(0.0764, grad_fn=<MeanBackward1>)\n",
      "12:57:18 - Training round: 9, worker: charlie, avg_loss: tensor(0.0864, grad_fn=<MeanBackward1>)\n",
      "12:57:20 - Starting training round 10/40\n",
      "12:57:20 - Training round 10, calling fit on worker: alice\n",
      "12:57:20 - Training round 10, calling fit on worker: bob\n",
      "12:57:20 - Training round 10, calling fit on worker: charlie\n",
      "12:57:21 - Training round: 10, worker: charlie, avg_loss: tensor(0.4713, grad_fn=<MeanBackward1>)\n",
      "12:57:23 - Training round: 10, worker: alice, avg_loss: tensor(0.2760, grad_fn=<MeanBackward1>)\n",
      "12:57:24 - Training round: 10, worker: bob, avg_loss: tensor(0.0272, grad_fn=<MeanBackward1>)\n",
      "12:57:28 - alice: Prediction hist.: [ 1439  1570  2558  2736  594  16  152  525  18  392]\n",
      "12:57:28 - alice: Percentage numbers 0-3: 0.8303\n",
      "12:57:28 - alice: Percentage numbers 4-6: 0.0762\n",
      "12:57:28 - alice: Percentage numbers 7-9: 0.0935\n",
      "12:57:28 - alice: Test set: Average loss: 0.0103, Accuracy: 5640/10000 (56.40)\n",
      "12:57:31 - bob: Prediction hist.: [ 9  842  472  0  2292  3549  2292  544  0  0]\n",
      "12:57:31 - bob: Percentage numbers 0-3: 0.1323\n",
      "12:57:31 - bob: Percentage numbers 4-6: 0.8133\n",
      "12:57:31 - bob: Percentage numbers 7-9: 0.0544\n",
      "12:57:31 - bob: Test set: Average loss: 0.0208, Accuracy: 4550/10000 (45.50)\n",
      "12:57:35 - charlie: Prediction hist.: [ 85  455  202  36  0  0  246  1306  5308  2362]\n",
      "12:57:35 - charlie: Percentage numbers 0-3: 0.0778\n",
      "12:57:35 - charlie: Percentage numbers 4-6: 0.0246\n",
      "12:57:35 - charlie: Percentage numbers 7-9: 0.8976\n",
      "12:57:35 - charlie: Test set: Average loss: 0.0141, Accuracy: 3818/10000 (38.18)\n",
      "12:57:38 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "12:57:38 - Federated model: Prediction hist.: [ 970  1162  1052  935  1482  943  1164  997  849  446]\n",
      "12:57:38 - Federated model: Percentage numbers 0-3: 0.4119\n",
      "12:57:38 - Federated model: Percentage numbers 4-6: 0.3589\n",
      "12:57:38 - Federated model: Percentage numbers 7-9: 0.2292\n",
      "12:57:38 - Federated model: Test set: Average loss: 0.0036, Accuracy: 8638/10000 (86.38)\n",
      "12:57:38 - Starting training round 11/40\n",
      "12:57:38 - Training round 11, calling fit on worker: alice\n",
      "12:57:38 - Training round 11, calling fit on worker: bob\n",
      "12:57:38 - Training round 11, calling fit on worker: charlie\n",
      "12:57:39 - Training round: 11, worker: charlie, avg_loss: tensor(0.1660, grad_fn=<MeanBackward1>)\n",
      "12:57:42 - Training round: 11, worker: alice, avg_loss: tensor(0.0837, grad_fn=<MeanBackward1>)\n",
      "12:57:44 - Training round: 11, worker: bob, avg_loss: tensor(0.0569, grad_fn=<MeanBackward1>)\n",
      "12:57:46 - Starting training round 12/40\n",
      "12:57:46 - Training round 12, calling fit on worker: alice\n",
      "12:57:47 - Training round 12, calling fit on worker: bob\n",
      "12:57:47 - Training round 12, calling fit on worker: charlie\n",
      "12:57:49 - Training round: 12, worker: charlie, avg_loss: tensor(0.0545, grad_fn=<MeanBackward1>)\n",
      "12:57:50 - Training round: 12, worker: bob, avg_loss: tensor(0.0369, grad_fn=<MeanBackward1>)\n",
      "12:57:52 - Training round: 12, worker: alice, avg_loss: tensor(0.3129, grad_fn=<MeanBackward1>)\n",
      "12:57:54 - Starting training round 13/40\n",
      "12:57:54 - Training round 13, calling fit on worker: alice\n",
      "12:57:54 - Training round 13, calling fit on worker: bob\n",
      "12:57:54 - Training round 13, calling fit on worker: charlie\n",
      "12:57:55 - Training round: 13, worker: alice, avg_loss: tensor(0.0602, grad_fn=<MeanBackward1>)\n",
      "12:57:57 - Training round: 13, worker: charlie, avg_loss: tensor(0.0239, grad_fn=<MeanBackward1>)\n",
      "12:57:58 - Training round: 13, worker: bob, avg_loss: tensor(0.1299, grad_fn=<MeanBackward1>)\n",
      "12:58:02 - alice: Prediction hist.: [ 1388  1533  2127  3143  686  18  594  445  66  0]\n",
      "12:58:02 - alice: Percentage numbers 0-3: 0.8191\n",
      "12:58:02 - alice: Percentage numbers 4-6: 0.1298\n",
      "12:58:02 - alice: Percentage numbers 7-9: 0.0511\n",
      "12:58:02 - alice: Test set: Average loss: 0.0120, Accuracy: 5783/10000 (57.83)\n",
      "12:58:06 - bob: Prediction hist.: [ 112  1008  911  3  1901  4104  1247  691  23  0]\n",
      "12:58:06 - bob: Percentage numbers 0-3: 0.2034\n",
      "12:58:06 - bob: Percentage numbers 4-6: 0.7252\n",
      "12:58:06 - bob: Percentage numbers 7-9: 0.0714\n",
      "12:58:06 - bob: Test set: Average loss: 0.0139, Accuracy: 5391/10000 (53.91)\n",
      "12:58:09 - charlie: Prediction hist.: [ 177  35  272  63  0  0  275  1746  4743  2689]\n",
      "12:58:09 - charlie: Percentage numbers 0-3: 0.0547\n",
      "12:58:09 - charlie: Percentage numbers 4-6: 0.0275\n",
      "12:58:09 - charlie: Percentage numbers 7-9: 0.9178\n",
      "12:58:09 - charlie: Test set: Average loss: 0.0206, Accuracy: 3684/10000 (36.84)\n",
      "12:58:12 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "12:58:12 - Federated model: Prediction hist.: [ 999  1113  1096  1002  629  859  980  1064  1052  1206]\n",
      "12:58:12 - Federated model: Percentage numbers 0-3: 0.421\n",
      "12:58:12 - Federated model: Percentage numbers 4-6: 0.2468\n",
      "12:58:12 - Federated model: Percentage numbers 7-9: 0.3322\n",
      "12:58:12 - Federated model: Test set: Average loss: 0.0027, Accuracy: 8961/10000 (89.61)\n",
      "12:58:12 - Starting training round 14/40\n",
      "12:58:12 - Training round 14, calling fit on worker: alice\n",
      "12:58:12 - Training round 14, calling fit on worker: bob\n",
      "12:58:13 - Training round 14, calling fit on worker: charlie\n",
      "12:58:13 - Training round: 14, worker: bob, avg_loss: tensor(0.0447, grad_fn=<MeanBackward1>)\n",
      "12:58:15 - Training round: 14, worker: alice, avg_loss: tensor(0.0748, grad_fn=<MeanBackward1>)\n",
      "12:58:16 - Training round: 14, worker: charlie, avg_loss: tensor(0.1606, grad_fn=<MeanBackward1>)\n",
      "12:58:17 - Starting training round 15/40\n",
      "12:58:17 - Training round 15, calling fit on worker: alice\n",
      "12:58:18 - Training round 15, calling fit on worker: bob\n",
      "12:58:18 - Training round 15, calling fit on worker: charlie\n",
      "12:58:19 - Training round: 15, worker: alice, avg_loss: tensor(0.0483, grad_fn=<MeanBackward1>)\n",
      "12:58:20 - Training round: 15, worker: charlie, avg_loss: tensor(0.1088, grad_fn=<MeanBackward1>)\n",
      "12:58:21 - Training round: 15, worker: bob, avg_loss: tensor(0.1361, grad_fn=<MeanBackward1>)\n",
      "12:58:23 - Starting training round 16/40\n",
      "12:58:23 - Training round 16, calling fit on worker: alice\n",
      "12:58:23 - Training round 16, calling fit on worker: bob\n",
      "12:58:23 - Training round 16, calling fit on worker: charlie\n",
      "12:58:24 - Training round: 16, worker: bob, avg_loss: tensor(0.1105, grad_fn=<MeanBackward1>)\n",
      "12:58:25 - Training round: 16, worker: alice, avg_loss: tensor(0.0183, grad_fn=<MeanBackward1>)\n",
      "12:58:27 - Training round: 16, worker: charlie, avg_loss: tensor(0.0789, grad_fn=<MeanBackward1>)\n",
      "12:58:35 - alice: Prediction hist.: [ 1473  1461  1498  2426  806  218  662  697  233  526]\n",
      "12:58:35 - alice: Percentage numbers 0-3: 0.6858\n",
      "12:58:35 - alice: Percentage numbers 4-6: 0.1686\n",
      "12:58:35 - alice: Percentage numbers 7-9: 0.1456\n",
      "12:58:35 - alice: Test set: Average loss: 0.0068, Accuracy: 7122/10000 (71.22)\n",
      "12:58:38 - bob: Prediction hist.: [ 278  882  778  267  2448  2872  1527  897  51  0]\n",
      "12:58:38 - bob: Percentage numbers 0-3: 0.2205\n",
      "12:58:38 - bob: Percentage numbers 4-6: 0.6847\n",
      "12:58:38 - bob: Percentage numbers 7-9: 0.0948\n",
      "12:58:38 - bob: Test set: Average loss: 0.0096, Accuracy: 5762/10000 (57.62)\n",
      "12:58:42 - charlie: Prediction hist.: [ 690  509  291  161  0  10  701  1674  2572  3392]\n",
      "12:58:42 - charlie: Percentage numbers 0-3: 0.1651\n",
      "12:58:42 - charlie: Percentage numbers 4-6: 0.0711\n",
      "12:58:42 - charlie: Percentage numbers 7-9: 0.7638\n",
      "12:58:42 - charlie: Test set: Average loss: 0.0147, Accuracy: 5198/10000 (51.98)\n",
      "12:58:47 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "12:58:47 - Federated model: Prediction hist.: [ 980  1136  981  967  892  948  1026  1109  846  1115]\n",
      "12:58:47 - Federated model: Percentage numbers 0-3: 0.4064\n",
      "12:58:47 - Federated model: Percentage numbers 4-6: 0.2866\n",
      "12:58:47 - Federated model: Percentage numbers 7-9: 0.307\n",
      "12:58:47 - Federated model: Test set: Average loss: 0.0023, Accuracy: 9234/10000 (92.34)\n",
      "12:58:47 - Starting training round 17/40\n",
      "12:58:47 - Training round 17, calling fit on worker: alice\n",
      "12:58:47 - Training round 17, calling fit on worker: bob\n",
      "12:58:47 - Training round 17, calling fit on worker: charlie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:49 - Training round: 17, worker: charlie, avg_loss: tensor(0.0827, grad_fn=<MeanBackward1>)\n",
      "12:58:51 - Training round: 17, worker: alice, avg_loss: tensor(0.0708, grad_fn=<MeanBackward1>)\n",
      "12:58:54 - Training round: 17, worker: bob, avg_loss: tensor(0.0086, grad_fn=<MeanBackward1>)\n",
      "12:58:55 - Starting training round 18/40\n",
      "12:58:55 - Training round 18, calling fit on worker: alice\n",
      "12:58:55 - Training round 18, calling fit on worker: bob\n",
      "12:58:55 - Training round 18, calling fit on worker: charlie\n",
      "12:58:56 - Training round: 18, worker: charlie, avg_loss: tensor(0.1544, grad_fn=<MeanBackward1>)\n",
      "12:58:57 - Training round: 18, worker: bob, avg_loss: tensor(0.1273, grad_fn=<MeanBackward1>)\n",
      "12:58:59 - Training round: 18, worker: alice, avg_loss: tensor(0.1713, grad_fn=<MeanBackward1>)\n",
      "12:59:00 - Starting training round 19/40\n",
      "12:59:00 - Training round 19, calling fit on worker: alice\n",
      "12:59:00 - Training round 19, calling fit on worker: bob\n",
      "12:59:00 - Training round 19, calling fit on worker: charlie\n",
      "12:59:01 - Training round: 19, worker: alice, avg_loss: tensor(0.4110, grad_fn=<MeanBackward1>)\n",
      "12:59:03 - Training round: 19, worker: charlie, avg_loss: tensor(1.0324, grad_fn=<MeanBackward1>)\n",
      "12:59:04 - Training round: 19, worker: bob, avg_loss: tensor(0.0099, grad_fn=<MeanBackward1>)\n",
      "12:59:08 - alice: Prediction hist.: [ 2015  2684  651  1276  1142  386  381  772  242  451]\n",
      "12:59:08 - alice: Percentage numbers 0-3: 0.6626\n",
      "12:59:08 - alice: Percentage numbers 4-6: 0.1909\n",
      "12:59:08 - alice: Percentage numbers 7-9: 0.1465\n",
      "12:59:08 - alice: Test set: Average loss: 0.0081, Accuracy: 6691/10000 (66.91)\n",
      "12:59:11 - bob: Prediction hist.: [ 165  1042  735  209  2225  2813  1636  783  392  0]\n",
      "12:59:11 - bob: Percentage numbers 0-3: 0.2151\n",
      "12:59:11 - bob: Percentage numbers 4-6: 0.6674\n",
      "12:59:11 - bob: Percentage numbers 7-9: 0.1175\n",
      "12:59:11 - bob: Test set: Average loss: 0.0106, Accuracy: 6028/10000 (60.28)\n",
      "12:59:17 - charlie: Prediction hist.: [ 202  639  488  282  592  60  813  2697  3539  688]\n",
      "12:59:17 - charlie: Percentage numbers 0-3: 0.1611\n",
      "12:59:17 - charlie: Percentage numbers 4-6: 0.1465\n",
      "12:59:17 - charlie: Percentage numbers 7-9: 0.6924\n",
      "12:59:17 - charlie: Test set: Average loss: 0.0094, Accuracy: 5454/10000 (54.54)\n",
      "12:59:20 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "12:59:20 - Federated model: Prediction hist.: [ 974  1192  848  943  1382  899  1034  1218  1017  493]\n",
      "12:59:20 - Federated model: Percentage numbers 0-3: 0.3957\n",
      "12:59:20 - Federated model: Percentage numbers 4-6: 0.3315\n",
      "12:59:20 - Federated model: Percentage numbers 7-9: 0.2728\n",
      "12:59:20 - Federated model: Test set: Average loss: 0.0025, Accuracy: 8901/10000 (89.01)\n",
      "12:59:20 - Starting training round 20/40\n",
      "12:59:20 - Training round 20, calling fit on worker: alice\n",
      "12:59:20 - Training round 20, calling fit on worker: bob\n",
      "12:59:20 - Training round 20, calling fit on worker: charlie\n",
      "12:59:21 - Training round: 20, worker: charlie, avg_loss: tensor(0.0657, grad_fn=<MeanBackward1>)\n",
      "12:59:22 - Training round: 20, worker: alice, avg_loss: tensor(0.0528, grad_fn=<MeanBackward1>)\n",
      "12:59:24 - Training round: 20, worker: bob, avg_loss: tensor(0.0152, grad_fn=<MeanBackward1>)\n",
      "12:59:25 - Starting training round 21/40\n",
      "12:59:25 - Training round 21, calling fit on worker: alice\n",
      "12:59:25 - Training round 21, calling fit on worker: bob\n",
      "12:59:25 - Training round 21, calling fit on worker: charlie\n",
      "12:59:26 - Training round: 21, worker: alice, avg_loss: tensor(0.0879, grad_fn=<MeanBackward1>)\n",
      "12:59:27 - Training round: 21, worker: bob, avg_loss: tensor(0.0958, grad_fn=<MeanBackward1>)\n",
      "12:59:29 - Training round: 21, worker: charlie, avg_loss: tensor(0.1686, grad_fn=<MeanBackward1>)\n",
      "12:59:30 - Starting training round 22/40\n",
      "12:59:30 - Training round 22, calling fit on worker: alice\n",
      "12:59:30 - Training round 22, calling fit on worker: bob\n",
      "12:59:30 - Training round 22, calling fit on worker: charlie\n",
      "12:59:31 - Training round: 22, worker: charlie, avg_loss: tensor(0.1693, grad_fn=<MeanBackward1>)\n",
      "12:59:33 - Training round: 22, worker: bob, avg_loss: tensor(0.0040, grad_fn=<MeanBackward1>)\n",
      "12:59:34 - Training round: 22, worker: alice, avg_loss: tensor(0.1142, grad_fn=<MeanBackward1>)\n",
      "12:59:39 - alice: Prediction hist.: [ 1912  1412  1628  1751  886  326  388  590  420  687]\n",
      "12:59:39 - alice: Percentage numbers 0-3: 0.6703\n",
      "12:59:39 - alice: Percentage numbers 4-6: 0.16\n",
      "12:59:39 - alice: Percentage numbers 7-9: 0.1697\n",
      "12:59:39 - alice: Test set: Average loss: 0.0064, Accuracy: 7317/10000 (73.17)\n",
      "12:59:42 - bob: Prediction hist.: [ 564  1092  823  77  1897  3015  1226  908  392  6]\n",
      "12:59:42 - bob: Percentage numbers 0-3: 0.2556\n",
      "12:59:42 - bob: Percentage numbers 4-6: 0.6138\n",
      "12:59:42 - bob: Percentage numbers 7-9: 0.1306\n",
      "12:59:42 - bob: Test set: Average loss: 0.0083, Accuracy: 6540/10000 (65.40)\n",
      "12:59:45 - charlie: Prediction hist.: [ 651  935  507  455  35  99  823  1193  3051  2251]\n",
      "12:59:45 - charlie: Percentage numbers 0-3: 0.2548\n",
      "12:59:45 - charlie: Percentage numbers 4-6: 0.0957\n",
      "12:59:45 - charlie: Percentage numbers 7-9: 0.6495\n",
      "12:59:45 - charlie: Test set: Average loss: 0.0077, Accuracy: 6379/10000 (63.79)\n",
      "12:59:48 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "12:59:48 - Federated model: Prediction hist.: [ 1018  1152  1025  948  975  924  982  993  987  996]\n",
      "12:59:48 - Federated model: Percentage numbers 0-3: 0.4143\n",
      "12:59:48 - Federated model: Percentage numbers 4-6: 0.2881\n",
      "12:59:48 - Federated model: Percentage numbers 7-9: 0.2976\n",
      "12:59:48 - Federated model: Test set: Average loss: 0.0016, Accuracy: 9433/10000 (94.33)\n",
      "12:59:48 - Starting training round 23/40\n",
      "12:59:48 - Training round 23, calling fit on worker: alice\n",
      "12:59:48 - Training round 23, calling fit on worker: bob\n",
      "12:59:48 - Training round 23, calling fit on worker: charlie\n",
      "12:59:49 - Training round: 23, worker: bob, avg_loss: tensor(0.2969, grad_fn=<MeanBackward1>)\n",
      "12:59:51 - Training round: 23, worker: alice, avg_loss: tensor(0.0093, grad_fn=<MeanBackward1>)\n",
      "12:59:53 - Training round: 23, worker: charlie, avg_loss: tensor(0.0048, grad_fn=<MeanBackward1>)\n",
      "12:59:54 - Starting training round 24/40\n",
      "12:59:54 - Training round 24, calling fit on worker: alice\n",
      "12:59:54 - Training round 24, calling fit on worker: bob\n",
      "12:59:54 - Training round 24, calling fit on worker: charlie\n",
      "12:59:55 - Training round: 24, worker: charlie, avg_loss: tensor(0.0658, grad_fn=<MeanBackward1>)\n",
      "12:59:57 - Training round: 24, worker: bob, avg_loss: tensor(0.1193, grad_fn=<MeanBackward1>)\n",
      "12:59:58 - Training round: 24, worker: alice, avg_loss: tensor(0.0895, grad_fn=<MeanBackward1>)\n",
      "12:59:59 - Starting training round 25/40\n",
      "12:59:59 - Training round 25, calling fit on worker: alice\n",
      "12:59:59 - Training round 25, calling fit on worker: bob\n",
      "12:59:59 - Training round 25, calling fit on worker: charlie\n",
      "13:00:00 - Training round: 25, worker: bob, avg_loss: tensor(0.5557, grad_fn=<MeanBackward1>)\n",
      "13:00:02 - Training round: 25, worker: alice, avg_loss: tensor(0.1614, grad_fn=<MeanBackward1>)\n",
      "13:00:03 - Training round: 25, worker: charlie, avg_loss: tensor(0.0701, grad_fn=<MeanBackward1>)\n",
      "13:00:07 - alice: Prediction hist.: [ 1727  1286  1282  1825  942  387  649  845  313  744]\n",
      "13:00:07 - alice: Percentage numbers 0-3: 0.612\n",
      "13:00:07 - alice: Percentage numbers 4-6: 0.1978\n",
      "13:00:07 - alice: Percentage numbers 7-9: 0.1902\n",
      "13:00:07 - alice: Test set: Average loss: 0.0051, Accuracy: 7868/10000 (78.68)\n",
      "13:00:10 - bob: Prediction hist.: [ 592  1086  905  549  2468  1658  1192  974  569  7]\n",
      "13:00:10 - bob: Percentage numbers 0-3: 0.3132\n",
      "13:00:10 - bob: Percentage numbers 4-6: 0.5318\n",
      "13:00:10 - bob: Percentage numbers 7-9: 0.155\n",
      "13:00:10 - bob: Test set: Average loss: 0.0063, Accuracy: 7303/10000 (73.03)\n",
      "13:00:13 - charlie: Prediction hist.: [ 574  491  293  639  5  183  661  1372  3786  1996]\n",
      "13:00:13 - charlie: Percentage numbers 0-3: 0.1997\n",
      "13:00:13 - charlie: Percentage numbers 4-6: 0.0849\n",
      "13:00:13 - charlie: Percentage numbers 7-9: 0.7154\n",
      "13:00:13 - charlie: Test set: Average loss: 0.0101, Accuracy: 5735/10000 (57.35)\n",
      "13:00:16 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "13:00:16 - Federated model: Prediction hist.: [ 1008  1129  974  1014  1009  869  964  1070  989  974]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:16 - Federated model: Percentage numbers 0-3: 0.4125\n",
      "13:00:16 - Federated model: Percentage numbers 4-6: 0.2842\n",
      "13:00:16 - Federated model: Percentage numbers 7-9: 0.3033\n",
      "13:00:16 - Federated model: Test set: Average loss: 0.0014, Accuracy: 9508/10000 (95.08)\n",
      "13:00:16 - Starting training round 26/40\n",
      "13:00:16 - Training round 26, calling fit on worker: alice\n",
      "13:00:16 - Training round 26, calling fit on worker: bob\n",
      "13:00:16 - Training round 26, calling fit on worker: charlie\n",
      "13:00:17 - Training round: 26, worker: charlie, avg_loss: tensor(0.0452, grad_fn=<MeanBackward1>)\n",
      "13:00:18 - Training round: 26, worker: alice, avg_loss: tensor(0.0082, grad_fn=<MeanBackward1>)\n",
      "13:00:20 - Training round: 26, worker: bob, avg_loss: tensor(0.0671, grad_fn=<MeanBackward1>)\n",
      "13:00:21 - Starting training round 27/40\n",
      "13:00:21 - Training round 27, calling fit on worker: alice\n",
      "13:00:21 - Training round 27, calling fit on worker: bob\n",
      "13:00:21 - Training round 27, calling fit on worker: charlie\n",
      "13:00:22 - Training round: 27, worker: bob, avg_loss: tensor(0.0571, grad_fn=<MeanBackward1>)\n",
      "13:00:23 - Training round: 27, worker: charlie, avg_loss: tensor(0.0344, grad_fn=<MeanBackward1>)\n",
      "13:00:24 - Training round: 27, worker: alice, avg_loss: tensor(0.0102, grad_fn=<MeanBackward1>)\n",
      "13:00:26 - Starting training round 28/40\n",
      "13:00:26 - Training round 28, calling fit on worker: alice\n",
      "13:00:26 - Training round 28, calling fit on worker: bob\n",
      "13:00:26 - Training round 28, calling fit on worker: charlie\n",
      "13:00:27 - Training round: 28, worker: bob, avg_loss: tensor(0.0087, grad_fn=<MeanBackward1>)\n",
      "13:00:29 - Training round: 28, worker: charlie, avg_loss: tensor(0.0380, grad_fn=<MeanBackward1>)\n",
      "13:00:30 - Training round: 28, worker: alice, avg_loss: tensor(0.0279, grad_fn=<MeanBackward1>)\n",
      "13:00:34 - alice: Prediction hist.: [ 1189  1307  1237  1459  1029  636  856  883  570  834]\n",
      "13:00:34 - alice: Percentage numbers 0-3: 0.5192\n",
      "13:00:34 - alice: Percentage numbers 4-6: 0.2521\n",
      "13:00:34 - alice: Percentage numbers 7-9: 0.2287\n",
      "13:00:34 - alice: Test set: Average loss: 0.0030, Accuracy: 8762/10000 (87.62)\n",
      "13:00:39 - bob: Prediction hist.: [ 813  1109  926  302  1652  2224  1082  1002  639  251]\n",
      "13:00:39 - bob: Percentage numbers 0-3: 0.315\n",
      "13:00:39 - bob: Percentage numbers 4-6: 0.4958\n",
      "13:00:39 - bob: Percentage numbers 7-9: 0.1892\n",
      "13:00:39 - bob: Test set: Average loss: 0.0048, Accuracy: 7687/10000 (76.87)\n",
      "13:00:42 - charlie: Prediction hist.: [ 735  670  615  622  31  288  813  1259  2125  2842]\n",
      "13:00:42 - charlie: Percentage numbers 0-3: 0.2642\n",
      "13:00:42 - charlie: Percentage numbers 4-6: 0.1132\n",
      "13:00:42 - charlie: Percentage numbers 7-9: 0.6226\n",
      "13:00:42 - charlie: Test set: Average loss: 0.0076, Accuracy: 6646/10000 (66.46)\n",
      "13:00:45 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "13:00:45 - Federated model: Prediction hist.: [ 988  1130  990  966  955  939  966  1054  969  1043]\n",
      "13:00:45 - Federated model: Percentage numbers 0-3: 0.4074\n",
      "13:00:45 - Federated model: Percentage numbers 4-6: 0.286\n",
      "13:00:45 - Federated model: Percentage numbers 7-9: 0.3066\n",
      "13:00:45 - Federated model: Test set: Average loss: 0.0013, Accuracy: 9517/10000 (95.17)\n",
      "13:00:45 - Starting training round 29/40\n",
      "13:00:45 - Training round 29, calling fit on worker: alice\n",
      "13:00:45 - Training round 29, calling fit on worker: bob\n",
      "13:00:45 - Training round 29, calling fit on worker: charlie\n",
      "13:00:46 - Training round: 29, worker: bob, avg_loss: tensor(0.0142, grad_fn=<MeanBackward1>)\n",
      "13:00:47 - Training round: 29, worker: charlie, avg_loss: tensor(0.0614, grad_fn=<MeanBackward1>)\n",
      "13:00:49 - Training round: 29, worker: alice, avg_loss: tensor(0.0318, grad_fn=<MeanBackward1>)\n",
      "13:00:50 - Starting training round 30/40\n",
      "13:00:50 - Training round 30, calling fit on worker: alice\n",
      "13:00:50 - Training round 30, calling fit on worker: bob\n",
      "13:00:50 - Training round 30, calling fit on worker: charlie\n",
      "13:00:51 - Training round: 30, worker: bob, avg_loss: tensor(0.0379, grad_fn=<MeanBackward1>)\n",
      "13:00:52 - Training round: 30, worker: alice, avg_loss: tensor(0.0141, grad_fn=<MeanBackward1>)\n",
      "13:00:53 - Training round: 30, worker: charlie, avg_loss: tensor(0.0942, grad_fn=<MeanBackward1>)\n",
      "13:00:55 - Starting training round 31/40\n",
      "13:00:55 - Training round 31, calling fit on worker: alice\n",
      "13:00:55 - Training round 31, calling fit on worker: bob\n",
      "13:00:55 - Training round 31, calling fit on worker: charlie\n",
      "13:00:56 - Training round: 31, worker: charlie, avg_loss: tensor(0.1582, grad_fn=<MeanBackward1>)\n",
      "13:00:57 - Training round: 31, worker: alice, avg_loss: tensor(0.0627, grad_fn=<MeanBackward1>)\n",
      "13:00:59 - Training round: 31, worker: bob, avg_loss: tensor(0.0839, grad_fn=<MeanBackward1>)\n",
      "13:01:04 - alice: Prediction hist.: [ 1366  1382  1246  1927  1056  365  791  835  364  668]\n",
      "13:01:04 - alice: Percentage numbers 0-3: 0.5921\n",
      "13:01:04 - alice: Percentage numbers 4-6: 0.2212\n",
      "13:01:04 - alice: Percentage numbers 7-9: 0.1867\n",
      "13:01:04 - alice: Test set: Average loss: 0.0048, Accuracy: 8019/10000 (80.19)\n",
      "13:01:08 - bob: Prediction hist.: [ 730  1088  941  436  1730  2445  953  970  489  218]\n",
      "13:01:08 - bob: Percentage numbers 0-3: 0.3195\n",
      "13:01:08 - bob: Percentage numbers 4-6: 0.5128\n",
      "13:01:08 - bob: Percentage numbers 7-9: 0.1677\n",
      "13:01:08 - bob: Test set: Average loss: 0.0052, Accuracy: 7537/10000 (75.37)\n",
      "13:01:11 - charlie: Prediction hist.: [ 751  774  631  571  145  242  585  1488  2657  2156]\n",
      "13:01:11 - charlie: Percentage numbers 0-3: 0.2727\n",
      "13:01:11 - charlie: Percentage numbers 4-6: 0.0972\n",
      "13:01:11 - charlie: Percentage numbers 7-9: 0.6301\n",
      "13:01:11 - charlie: Test set: Average loss: 0.0074, Accuracy: 6623/10000 (66.23)\n",
      "13:01:14 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "13:01:14 - Federated model: Prediction hist.: [ 1021  1137  1018  1008  986  913  922  1054  948  993]\n",
      "13:01:14 - Federated model: Percentage numbers 0-3: 0.4184\n",
      "13:01:14 - Federated model: Percentage numbers 4-6: 0.2821\n",
      "13:01:14 - Federated model: Percentage numbers 7-9: 0.2995\n",
      "13:01:14 - Federated model: Test set: Average loss: 0.0012, Accuracy: 9568/10000 (95.68)\n",
      "13:01:14 - Starting training round 32/40\n",
      "13:01:15 - Training round 32, calling fit on worker: alice\n",
      "13:01:15 - Training round 32, calling fit on worker: bob\n",
      "13:01:15 - Training round 32, calling fit on worker: charlie\n",
      "13:01:16 - Training round: 32, worker: bob, avg_loss: tensor(0.0069, grad_fn=<MeanBackward1>)\n",
      "13:01:17 - Training round: 32, worker: charlie, avg_loss: tensor(0.1031, grad_fn=<MeanBackward1>)\n",
      "13:01:18 - Training round: 32, worker: alice, avg_loss: tensor(0.0658, grad_fn=<MeanBackward1>)\n",
      "13:01:19 - Starting training round 33/40\n",
      "13:01:19 - Training round 33, calling fit on worker: alice\n",
      "13:01:19 - Training round 33, calling fit on worker: bob\n",
      "13:01:20 - Training round 33, calling fit on worker: charlie\n",
      "13:01:20 - Training round: 33, worker: charlie, avg_loss: tensor(0.1788, grad_fn=<MeanBackward1>)\n",
      "13:01:22 - Training round: 33, worker: bob, avg_loss: tensor(0.0056, grad_fn=<MeanBackward1>)\n",
      "13:01:23 - Training round: 33, worker: alice, avg_loss: tensor(0.0649, grad_fn=<MeanBackward1>)\n",
      "13:01:25 - Starting training round 34/40\n",
      "13:01:25 - Training round 34, calling fit on worker: alice\n",
      "13:01:25 - Training round 34, calling fit on worker: bob\n",
      "13:01:25 - Training round 34, calling fit on worker: charlie\n",
      "13:01:26 - Training round: 34, worker: bob, avg_loss: tensor(0.0310, grad_fn=<MeanBackward1>)\n",
      "13:01:28 - Training round: 34, worker: alice, avg_loss: tensor(0.0300, grad_fn=<MeanBackward1>)\n",
      "13:01:29 - Training round: 34, worker: charlie, avg_loss: tensor(0.0364, grad_fn=<MeanBackward1>)\n",
      "13:01:34 - alice: Prediction hist.: [ 1219  1235  1398  1898  870  270  779  869  532  930]\n",
      "13:01:34 - alice: Percentage numbers 0-3: 0.575\n",
      "13:01:34 - alice: Percentage numbers 4-6: 0.1919\n",
      "13:01:34 - alice: Percentage numbers 7-9: 0.2331\n",
      "13:01:34 - alice: Test set: Average loss: 0.0042, Accuracy: 8268/10000 (82.68)\n",
      "13:01:38 - bob: Prediction hist.: [ 796  1046  984  674  2183  1690  1156  976  423  72]\n",
      "13:01:38 - bob: Percentage numbers 0-3: 0.35\n",
      "13:01:38 - bob: Percentage numbers 4-6: 0.5029\n",
      "13:01:38 - bob: Percentage numbers 7-9: 0.1471\n",
      "13:01:38 - bob: Test set: Average loss: 0.0056, Accuracy: 7639/10000 (76.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:42 - charlie: Prediction hist.: [ 571  729  707  577  453  447  812  1381  2370  1953]\n",
      "13:01:42 - charlie: Percentage numbers 0-3: 0.2584\n",
      "13:01:42 - charlie: Percentage numbers 4-6: 0.1712\n",
      "13:01:42 - charlie: Percentage numbers 7-9: 0.5704\n",
      "13:01:42 - charlie: Test set: Average loss: 0.0063, Accuracy: 7190/10000 (71.90)\n",
      "13:01:45 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "13:01:45 - Federated model: Prediction hist.: [ 974  1122  1049  1004  1011  894  955  1055  931  1005]\n",
      "13:01:45 - Federated model: Percentage numbers 0-3: 0.4149\n",
      "13:01:45 - Federated model: Percentage numbers 4-6: 0.286\n",
      "13:01:45 - Federated model: Percentage numbers 7-9: 0.2991\n",
      "13:01:45 - Federated model: Test set: Average loss: 0.0012, Accuracy: 9563/10000 (95.63)\n",
      "13:01:45 - Starting training round 35/40\n",
      "13:01:46 - Training round 35, calling fit on worker: alice\n",
      "13:01:46 - Training round 35, calling fit on worker: bob\n",
      "13:01:46 - Training round 35, calling fit on worker: charlie\n",
      "13:01:47 - Training round: 35, worker: alice, avg_loss: tensor(0.0645, grad_fn=<MeanBackward1>)\n",
      "13:01:48 - Training round: 35, worker: charlie, avg_loss: tensor(0.2510, grad_fn=<MeanBackward1>)\n",
      "13:01:49 - Training round: 35, worker: bob, avg_loss: tensor(0.0062, grad_fn=<MeanBackward1>)\n",
      "13:01:50 - Starting training round 36/40\n",
      "13:01:50 - Training round 36, calling fit on worker: alice\n",
      "13:01:50 - Training round 36, calling fit on worker: bob\n",
      "13:01:51 - Training round 36, calling fit on worker: charlie\n",
      "13:01:51 - Training round: 36, worker: charlie, avg_loss: tensor(0.1156, grad_fn=<MeanBackward1>)\n",
      "13:01:53 - Training round: 36, worker: bob, avg_loss: tensor(0.0181, grad_fn=<MeanBackward1>)\n",
      "13:01:54 - Training round: 36, worker: alice, avg_loss: tensor(0.0522, grad_fn=<MeanBackward1>)\n",
      "13:01:55 - Starting training round 37/40\n",
      "13:01:55 - Training round 37, calling fit on worker: alice\n",
      "13:01:55 - Training round 37, calling fit on worker: bob\n",
      "13:01:55 - Training round 37, calling fit on worker: charlie\n",
      "13:01:56 - Training round: 37, worker: bob, avg_loss: tensor(0.0030, grad_fn=<MeanBackward1>)\n",
      "13:01:57 - Training round: 37, worker: charlie, avg_loss: tensor(0.0209, grad_fn=<MeanBackward1>)\n",
      "13:01:59 - Training round: 37, worker: alice, avg_loss: tensor(0.1230, grad_fn=<MeanBackward1>)\n",
      "13:02:03 - alice: Prediction hist.: [ 1295  1190  1148  3551  791  214  590  726  114  381]\n",
      "13:02:03 - alice: Percentage numbers 0-3: 0.7184\n",
      "13:02:03 - alice: Percentage numbers 4-6: 0.1595\n",
      "13:02:03 - alice: Percentage numbers 7-9: 0.1221\n",
      "13:02:03 - alice: Test set: Average loss: 0.0084, Accuracy: 6768/10000 (67.68)\n",
      "13:02:06 - bob: Prediction hist.: [ 851  1045  996  552  1520  1889  1130  977  608  432]\n",
      "13:02:06 - bob: Percentage numbers 0-3: 0.3444\n",
      "13:02:06 - bob: Percentage numbers 4-6: 0.4539\n",
      "13:02:06 - bob: Percentage numbers 7-9: 0.2017\n",
      "13:02:06 - bob: Test set: Average loss: 0.0038, Accuracy: 8136/10000 (81.36)\n",
      "13:02:09 - charlie: Prediction hist.: [ 838  931  560  553  358  403  857  1146  2509  1845]\n",
      "13:02:09 - charlie: Percentage numbers 0-3: 0.2882\n",
      "13:02:09 - charlie: Percentage numbers 4-6: 0.1618\n",
      "13:02:09 - charlie: Percentage numbers 7-9: 0.55\n",
      "13:02:09 - charlie: Test set: Average loss: 0.0056, Accuracy: 7408/10000 (74.08)\n",
      "13:02:12 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "13:02:12 - Federated model: Prediction hist.: [ 1008  1131  1014  1067  956  897  945  1020  964  998]\n",
      "13:02:12 - Federated model: Percentage numbers 0-3: 0.422\n",
      "13:02:12 - Federated model: Percentage numbers 4-6: 0.2798\n",
      "13:02:12 - Federated model: Percentage numbers 7-9: 0.2982\n",
      "13:02:12 - Federated model: Test set: Average loss: 0.0011, Accuracy: 9602/10000 (96.02)\n",
      "13:02:12 - Starting training round 38/40\n",
      "13:02:12 - Training round 38, calling fit on worker: alice\n",
      "13:02:12 - Training round 38, calling fit on worker: bob\n",
      "13:02:12 - Training round 38, calling fit on worker: charlie\n",
      "13:02:13 - Training round: 38, worker: bob, avg_loss: tensor(0.0511, grad_fn=<MeanBackward1>)\n",
      "13:02:15 - Training round: 38, worker: charlie, avg_loss: tensor(0.1040, grad_fn=<MeanBackward1>)\n",
      "13:02:16 - Training round: 38, worker: alice, avg_loss: tensor(0.1539, grad_fn=<MeanBackward1>)\n",
      "13:02:17 - Starting training round 39/40\n",
      "13:02:17 - Training round 39, calling fit on worker: alice\n",
      "13:02:17 - Training round 39, calling fit on worker: bob\n",
      "13:02:17 - Training round 39, calling fit on worker: charlie\n",
      "13:02:18 - Training round: 39, worker: bob, avg_loss: tensor(0.0478, grad_fn=<MeanBackward1>)\n",
      "13:02:19 - Training round: 39, worker: alice, avg_loss: tensor(0.0272, grad_fn=<MeanBackward1>)\n",
      "13:02:21 - Training round: 39, worker: charlie, avg_loss: tensor(0.0178, grad_fn=<MeanBackward1>)\n",
      "13:02:22 - Starting training round 40/40\n",
      "13:02:22 - Training round 40, calling fit on worker: alice\n",
      "13:02:22 - Training round 40, calling fit on worker: bob\n",
      "13:02:22 - Training round 40, calling fit on worker: charlie\n",
      "13:02:23 - Training round: 40, worker: bob, avg_loss: tensor(0.0045, grad_fn=<MeanBackward1>)\n",
      "13:02:25 - Training round: 40, worker: alice, avg_loss: tensor(0.0398, grad_fn=<MeanBackward1>)\n",
      "13:02:26 - Training round: 40, worker: charlie, avg_loss: tensor(0.0553, grad_fn=<MeanBackward1>)\n",
      "13:02:30 - alice: Prediction hist.: [ 1039  1221  1629  1726  923  381  866  854  539  822]\n",
      "13:02:30 - alice: Percentage numbers 0-3: 0.5615\n",
      "13:02:30 - alice: Percentage numbers 4-6: 0.217\n",
      "13:02:30 - alice: Percentage numbers 7-9: 0.2215\n",
      "13:02:30 - alice: Test set: Average loss: 0.0038, Accuracy: 8437/10000 (84.37)\n",
      "13:02:33 - bob: Prediction hist.: [ 876  1125  999  494  1710  1777  1271  983  607  158]\n",
      "13:02:33 - bob: Percentage numbers 0-3: 0.3494\n",
      "13:02:33 - bob: Percentage numbers 4-6: 0.4758\n",
      "13:02:33 - bob: Percentage numbers 7-9: 0.1748\n",
      "13:02:33 - bob: Test set: Average loss: 0.0045, Accuracy: 7908/10000 (79.08)\n",
      "13:02:36 - charlie: Prediction hist.: [ 754  760  504  518  373  155  856  1270  2871  1939]\n",
      "13:02:36 - charlie: Percentage numbers 0-3: 0.2536\n",
      "13:02:36 - charlie: Percentage numbers 4-6: 0.1384\n",
      "13:02:36 - charlie: Percentage numbers 7-9: 0.608\n",
      "13:02:36 - charlie: Test set: Average loss: 0.0072, Accuracy: 6842/10000 (68.42)\n",
      "13:02:39 - Target histogram: [ 980  1135  1032  1010  982  892  958  1028  974  1009]\n",
      "13:02:39 - Federated model: Prediction hist.: [ 990  1132  1037  989  985  877  989  1043  992  966]\n",
      "13:02:39 - Federated model: Percentage numbers 0-3: 0.4148\n",
      "13:02:39 - Federated model: Percentage numbers 4-6: 0.2851\n",
      "13:02:39 - Federated model: Percentage numbers 7-9: 0.3001\n",
      "13:02:39 - Federated model: Test set: Average loss: 0.0010, Accuracy: 9648/10000 (96.48)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = args.lr\n",
    "import numpy as np\n",
    "for curr_round in range(1, args.training_rounds + 1):\n",
    "    global traced_model\n",
    "    \n",
    "    logger.info(\"Starting training round %s/%s\", curr_round, args.training_rounds)\n",
    "\n",
    "    # For each of the workers we ask the model to train with their part of their data\n",
    "    # in a async fashion and then we gather the results\n",
    "    results = await asyncio.gather(\n",
    "        *[\n",
    "            rwc.fit_model_on_worker(\n",
    "                worker=worker,\n",
    "                traced_model=traced_model,\n",
    "                batch_size=args.batch_size,\n",
    "                curr_round=curr_round,\n",
    "                max_nr_batches=args.federate_after_n_batches,\n",
    "                lr=learning_rate,\n",
    "            )\n",
    "            for worker in worker_instances\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    models = {}\n",
    "    loss_values = {}\n",
    "\n",
    "    \"\"\"\n",
    "    # Run evaluation every 10 rounds\n",
    "    run_evaluation = (curr_round) % 10 == 1 or curr_round == args.training_rounds\n",
    "    if run_evaluation:\n",
    "        rwc.evaluate_models_on_test_data(test_loader, results)\n",
    "         \n",
    "    # Store models and loss_values for each worker\n",
    "    for worker_id, worker_model, worker_loss in results:\n",
    "        if worker_model is not None:\n",
    "            models[worker_id] = worker_model\n",
    "            loss_values[worker_id] = worker_loss\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    test_models = curr_round % 10 == 1 or curr_round == args.training_rounds\n",
    "    if test_models:\n",
    "            np.set_printoptions(formatter={\"float\": \"{: .0f}\".format})\n",
    "            for worker_id, worker_model, _ in results:\n",
    "                rwc.evaluate_model_on_worker(\n",
    "                    model_identifier=worker_id,\n",
    "                    worker=testing,\n",
    "                    dataset_key=\"mnist_testing\",\n",
    "                    model=worker_model,\n",
    "                    nr_bins=10,\n",
    "                    batch_size=128,\n",
    "                    print_target_hist=False,\n",
    "                )\n",
    "\n",
    "    for worker_id, worker_model, worker_loss in results:\n",
    "        if worker_model is not None:\n",
    "                models[worker_id] = worker_model\n",
    "                loss_values[worker_id] = worker_loss\n",
    "\n",
    "    averaged_model = utils.federated_avg(models)\n",
    "    \n",
    "    if test_models:\n",
    "            rwc.evaluate_model_on_worker(\n",
    "                model_identifier=\"Federated model\",\n",
    "                worker=testing,\n",
    "                dataset_key=\"mnist_testing\",\n",
    "                model=averaged_model,\n",
    "                nr_bins=10,\n",
    "                batch_size=128,\n",
    "                print_target_hist=True,\n",
    "            )\n",
    "    \"\"\"\n",
    "    # Average model\n",
    "    avg_model = utils.federated_avg(models)\n",
    "    \n",
    "    \n",
    "    if run_evaluation:\n",
    "        rwc.evaluate_model(\"Federated model\", avg_model, \"cpu\", test_loader)\n",
    "    \"\"\"\n",
    "    # decay learning rate\n",
    "    learning_rate = max(0.98 * learning_rate, args.lr * 0.01)\n",
    "    \n",
    "    # Use averaged model in the next round\n",
    "    traced_model = averaged_model\n",
    "\n",
    "# Save model\n",
    "if args.save_model:\n",
    "    torch.save(averaged_model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 40 rounds of training we achieve an accuracy > 95% on the entire testing dataset. \n",
    "This is impressing, given that no worker has access to more than 4 digits!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
